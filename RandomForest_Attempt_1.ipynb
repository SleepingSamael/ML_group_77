{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8016ff02-37ec-4623-a77f-2fe3616572b9",
   "metadata": {},
   "source": [
    "# <b> Random Forest Classifier (Attempt 1)</b>\n",
    "Behold! My first attempt at the Random Forest Classifier for the Diabetes Health Indicator Dataset. \n",
    "\n",
    "<b>*Note that you only uncomment the line with pickle if you store the files only locally. They are too large for github and will therefor give error when pushing to main branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0ceebc5-10f2-4acf-a698-9ce38ab7febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75edea-f021-443e-a33e-b1568d4e1d0f",
   "metadata": {},
   "source": [
    "### <b>Loading the data</b> \n",
    "First, the data is loaded and is split between the data (features) and the labels. The data (features) is stored in a dataframe and the labels are stored as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76fa0281-e635-4f65-89e3-bfbbee743c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and split labels and features (data)\n",
    "data = pd.read_csv(\"./diabetes/training_data(no_pre-diabetes).csv\")\n",
    "labels = data[\"Diabetes_012\"]\n",
    "del data[\"Diabetes_012\"] # deletes the labels from the data dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26865823-3844-46a3-8085-f4083ad8ac20",
   "metadata": {},
   "source": [
    "### <b> Split data into training and validation set </b>\n",
    "Below the data is split up again into training and validation data. with an 80 to 20% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f406992-0285-4531-b34a-38b787079043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in training and validation set, with for each a set of data and a set of corresponding labels\n",
    "training_data, validation_data, training_labels, validation_labels = train_test_split(data, labels, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a91a2-aff2-48d4-bc07-1ef0abac7b9d",
   "metadata": {},
   "source": [
    "### <b>Fit model without feature selection or hyperparameter tuning</b>\n",
    "Here a Random Forest Classifier is trained based on just the training data and the default parameters of the function RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58675aa6-eaba-4467-be26-ef9b23f9466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier().fit(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84742cc6-1bcf-4255-9a67-00322f519687",
   "metadata": {},
   "source": [
    "Now the model is evaluated based on the validation set with the help of sklearn's accuracy_score function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a29e1e6e-c9b2-4349-9c91-f14216748e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy base model:  0.8616845953315555\n"
     ]
    }
   ],
   "source": [
    "pred_base_model = base_model.predict(validation_data)\n",
    "print(\"Accuracy base model: \", accuracy_score(validation_labels, pred_base_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b45368-5b4a-4399-9c92-78bb8f2bca24",
   "metadata": {},
   "source": [
    "Now the model is pickled to be able to use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23d216fa-6614-4556-8b2c-b509ecfbec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(base_model, open(\"RF_base_model.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b521e-2b98-4262-b748-ad2540d3aae0",
   "metadata": {},
   "source": [
    "## <b> GridSearchCV </b>\n",
    "To boost the performance of the model, GridSearchCV is performed. Which refers to sampling the data multiple times into training and validation set to determine the best hyperparameters for the model in combination with the given data. \n",
    "\n",
    "### <b>Set up the paramater grid</b>\n",
    "The next piece of code sets the parameter grid for the GridSearchCV later. <br>\n",
    "Initial search for the right parameters on the internet resulted into the use of default parameters for the following: <br>\n",
    "<ul>\n",
    "    <li> bootstrap (default = True) If it would be False then the complete data was used to create the tree.</li> \n",
    "    <li> max_features (default = auto) Refers to max_features=sqrt(n_features)</li>\n",
    "    <li> criterion (default = gini) meaning that the gini impurity is calculated to determine whether to split a node. Gini is faster than entropy calculation and the difference between           them should not be major.</li> \n",
    "    <li> max_depth (default = None) Tree kan have as many nodes and edges as seems fit.</li> \n",
    "    <li> min_samples_leaf (default = 1, meaning at least one sample needs to be present in the leaf)</li>\n",
    "</ul>\n",
    "<b> * Please note that using as many default parameters as possible significantly reduces the training time, which is already quite long for the RF algorithm </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63551151-1c7e-492f-b8d8-9641b1fb3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in the random forest\n",
    "n_estimators = [50, 100, 150, 200]\n",
    "    \n",
    "# Minimum no. of samples that need to be positive to create a new node split.\n",
    "min_samples_split = [2, 4, 8, 16, 32, 64]\n",
    "\n",
    "# Create random_grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7fc9e-cdc1-4323-a696-b17ad9182e1c",
   "metadata": {},
   "source": [
    "### <b> Initialize model and perform GridSearchCV </b>\n",
    "Now the Random Forest Classifier is initiated and a gridsearch is started with 4 crossvalidations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da922e02-b2eb-45f8-a09e-36e6960024ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7fa5f9-62c5-4649-9bd5-518626b746fc",
   "metadata": {},
   "source": [
    "### <b> Fit the model</b>\n",
    "Now the model is fitted with the training data and training labels.<br>\n",
    "<b> Note that running this piece of code can take quite some time (max 10 min.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a713403b-080d-4bff-afb7-7b7af1038e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
       "                         'n_estimators': [50, 100, 150, 200]})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.fit(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966ad83-6f42-4d67-9a81-8b66e72b30fb",
   "metadata": {},
   "source": [
    "### <b> Check best parameters and accuracy</b>\n",
    "Check which parameters where considered the best this round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35f0e55e-e592-444c-996b-c26eb43f26e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'min_samples_split': 32, 'n_estimators': 200}\n",
      "Accuracy base model:  0.8680969646121116\n"
     ]
    }
   ],
   "source": [
    "# Print out the best parameters according to GridSearchCV\n",
    "print(\"Best parameters: \", cv_model.best_params_)\n",
    "\n",
    "# Determine accuracy of model based on validation set\n",
    "pred_cv_model = cv_model.predict(validation_data)\n",
    "print(\"Accuracy GridSearchCV model: \", accuracy_score(validation_labels, pred_cv_model))\n",
    "\n",
    "# Pickle model\n",
    "# pickle.dump(cv_model, open(\"RF_cv_model.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec99566-c5d4-46c9-addc-863240aa1325",
   "metadata": {},
   "source": [
    "## <b>Feature selection</b>\n",
    "To boost the performance of the model, feature selection is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dc0391c-5a1f-44db-bbbe-fc32aabedc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = SelectFromModel(RandomForestClassifier())\n",
    "f_select_model = selection.fit(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bdc7f93-74aa-4166-95d4-33205629dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot of training data with important features: \n",
      "          BMI  GenHlth  MentHlth  PhysHlth   Age  Education  Income\n",
      "120489  31.0      5.0       0.0      15.0  11.0        5.0     3.0\n",
      "129057  21.0      3.0       2.0       0.0  13.0        6.0     8.0\n",
      "48071   32.0      3.0       0.0       0.0   6.0        6.0     8.0\n",
      "145333  44.0      4.0       5.0      20.0   5.0        4.0     3.0\n",
      "30240   25.0      1.0       4.0       0.0   3.0        6.0     7.0\n"
     ]
    }
   ],
   "source": [
    "# Determine which features were selected as best\n",
    "selected_features = training_data.columns[(f_select_model.get_support())]\n",
    "\n",
    "# Remove non important features from training and validation set\n",
    "f_select_training_data = training_data[selected_features]\n",
    "print(\"Snapshot of training data with important features:\", \"\\n\",f_select_training_data.head())\n",
    "\n",
    "f_select_validation_data = validation_data[selected_features]\n",
    "\n",
    "# Train model again with selected features\n",
    "f_model = RandomForestClassifier().fit(f_select_training_data, training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c22e02ab-7ccd-4da4-9be5-02830dbd3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy base model:  0.8443652054055674\n"
     ]
    }
   ],
   "source": [
    "# Determine accuracy of model based on validation set\n",
    "pred_f_model = f_model.predict(f_select_validation_data)\n",
    "print(\"Accuracy feature selection model: \", accuracy_score(validation_labels, pred_f_model))\n",
    "\n",
    "# Pickle model\n",
    "# pickle.dump(f_model, open(\"RF_feat_select_model.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ed8a3-e83d-4a4f-a8b8-63902c4d6e0d",
   "metadata": {},
   "source": [
    "## <b>Combining the feature selection and GridSearchCV</b>\n",
    "Let's take a look whether combining these two methods will boost the accuracy.\n",
    "The param_grid is reused as well as the earlier created data with feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bb22e12-31a8-47eb-8321-b2678cf221f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
       "                         'n_estimators': [50, 100, 150, 200]})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVF_model = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=4)\n",
    "CVF_model.fit(f_select_training_data, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48e59e-49a5-40a3-b347-8cd7a9de581a",
   "metadata": {},
   "source": [
    "Below the accuracy is determined for this combined classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b02be2a-4609-404a-a3ae-05d981046916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy base model:  0.8635723489048033\n"
     ]
    }
   ],
   "source": [
    "# Determine accuracy of model based on validation set\n",
    "pred_CVF_model = CVF_model.predict(f_select_validation_data)\n",
    "print(\"Accuracy base model: \", accuracy_score(validation_labels, pred_CVF_model))\n",
    "\n",
    "# Pickle model\n",
    "# pickle.dump(CVF_model, open(\"RF_combi_CVF_model.p\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
